MentorMindAI â€“ Smart Video Evaluation & Accessibility Engine

MentorMindAI is an AI-powered backend that evaluates videos for teaching quality and also converts videos into different accessibility modesâ€”Blind Mode, Deaf Mode, and Easy Mode.
This system uses ONNX machine-learning models for scoring and FastAPI for serving all endpoints.

ðŸš€ Project Overview

This project provides two major functionalities:

1. Video Scoring System (AI Evaluation)

Uploads a video and returns:

-Clarity score
-Engagement score
-Pace score
-Filler word score
-Technical depth score
-Weighted overall score

Models used:

-clarity_model.onnx
-engagement_cnn.onnx
-pace_model.onnx
-filler_model.onnx
-tech_depth_model.onnx

2. Accessibility Modes

Convert any uploaded video into:

Blind Mode

Generates audio narration of the video content.

Deaf Mode

Generates subtitles using Whisper STT.

Easy Mode

Simplified narration using text summarization + TTS.

ðŸ§± Project Architecture Overview
ðŸ“¦ MentorMindAI
 â”£ backend/
 â”‚ â”£ app/
 â”‚ â”‚ â”£ api/v1/
 â”‚ â”‚ â”‚ â”£ routes_upload.py      â†’ Upload & mode conversion APIs
 â”‚ â”‚ â”£ services/
 â”‚ â”‚ â”‚ â”£ video_scoring.py      â†’ ONNX scoring engine
 â”‚ â”‚ â”‚ â”£ mode_blind.py         â†’ Blind mode processing
 â”‚ â”‚ â”‚ â”£ mode_deaf.py          â†’ Deaf mode (subtitles)
 â”‚ â”‚ â”‚ â”£ mode_easy.py          â†’ Easy mode audio
 â”‚ â”‚ â”‚ â”£ video_processor.py    â†’ File handling utils
 â”‚ â”‚ â”£ main.py                 â†’ FastAPI entry point
 â”£ models/
 â”‚ â”£ clarity_model.onnx
 â”‚ â”£ engagement_cnn.onnx
 â”‚ â”£ pace_model.onnx
 â”‚ â”£ filler_model.onnx
 â”‚ â”£ tech_depth_model.onnx
 â”£ frontend/ (optional)
 â”£ README.md
 â”£ requirements.txt


                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚          Frontend            â”‚
                        â”‚        (React + Vite)        â”‚
                        â”‚ â”€ File Upload (Video)        â”‚
                        â”‚ â”€ Show Results Dashboard     â”‚
                        â”‚ â”€ Accessibility UI           â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â”‚  HTTP (REST)
                                        â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚           FastAPI API         â”‚
                        â”‚        /api/v1/score          â”‚
                        â”‚        /api/v1/results/{id}   â”‚
                        â”‚        /api/v1/upload         â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                   Upload Video â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â” Queue Job
                                â”‚                â”‚
                                â–¼                â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚     AWS S3      â”‚   â”‚      Redis       â”‚
                   â”‚   Storage Bucketâ”‚   â”‚  Task Queue      â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                       â”‚
                           â”‚ Fetch video           â”‚ Celery Task
                           â”‚                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                    â”‚             Celery Worker            â”‚
                    â”‚ â”€ Audio Extraction (librosa)         â”‚
                    â”‚ â”€ Transcript (ASR)                   â”‚
                    â”‚ â”€ Frame Sampling                     â”‚
                    â”‚ â”€ ONNX Model Inference:              â”‚
                    â”‚       â€¢ clarity_model.onnx           â”‚
                    â”‚       â€¢ engagement_cnn.onnx          â”‚
                    â”‚       â€¢ pace_estimator.onnx          â”‚
                    â”‚       â€¢ filler_detector.onnx         â”‚
                    â”‚       â€¢ tech_score_model.onnx        â”‚
                    â”‚ â”€ Scoring Engine                     â”‚
                    â”‚ â”€ Save Final JSON Output             â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ Writes result
                              â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   Results Store â”‚
                     â”‚  (DB / JSON)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    Frontend Fetches Final Results
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Results Dashboard â”‚
                    â”‚ Graphs + Badges   â”‚
                    â”‚ Accessibility Modesâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


âš™ï¸ Setup Instructions
1. Clone the repository
git clone https://github.com/your-repo/MentorMindAI
cd MentorMindAI

2. Create virtual environment
python -m venv venv

3. Activate environment

Windows:

venv\Scripts\activate


Mac/Linux:

source venv/bin/activate

4. Install dependencies
pip install -r requirements.txt

5. Ensure FFmpeg is installed (required for moviepy)

Windows:

choco install ffmpeg


Mac:

brew install ffmpeg

6. Run python models/generate_dummy_models

â–¶ï¸ How to Run Locally

Start FastAPI server:

uvicorn src.backend.app.main:app --reload


Server runs at:

ðŸ‘‰ http://localhost:8000

Open docs:

ðŸ‘‰ http://localhost:8000/docs

(Interactive Swagger UI)

ðŸ”¥ API Endpoints
1ï¸âƒ£ Upload Video & Get Scores
POST /upload/video

Response
{
  "file_id": "56c7e543-0b4e-49f6-9509-fb6cbe6bc9b6",
  "scores": {
    "clarity": 0.23,
    "engagement": 0.45,
    "pace": 0.31,
    "filler": -0.04,
    "tech": 0.12
  },
  "overall_score": 0.28
}

2ï¸âƒ£ Convert Video into Accessibility Mode
POST /convert?mode=blind
POST /convert?mode=deaf
POST /convert?mode=easy

Response Example
{
  "status": "success",
  "output_path": "/mnt/data/uploads/video_blind_mode.mp3"
}

ðŸ§ª Example Input & Output
Input

MP4 video file
Mode: "deaf"

Output

Extracted audio

Speech â†’ Text using Whisper

.srt subtitle file

1
00:00:01,000 --> 00:00:03,000
Hello students, today we will learn AI.

ðŸ“¦ List of Dependencies

fastapi
uvicorn[standard]
python-multipart
celery[redis]
redis
pydantic
requests
python-dotenv
celery==5.3.6
redis==5.0.1
opencv-python
python-dotenv
numpy
pydub
speechrecognition
transformers
torch
pillow
moviepy
onnxruntime

---



---
## *Contributions

Shravani Tanksale(AI Lead): Built scoring models, backend logic, Celery processing, accessibility modes, and end-to-end integration.

Vidyankshini Vibhute(Frontend): Developed UI, graphs, animations, upload flow, dashboard, and linked frontend with backend.

Devika Mule(Cloud/DevOps): Set up AWS S3, Redis, Celery, cloud architecture, deployment environment, and backend optimizations.


